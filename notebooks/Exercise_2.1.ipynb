{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.1\n",
    "\n",
    "## Classification of CIFAR10 images\n",
    "### Optimizers\n",
    "In this exercise we will classify the images from the CIFAR10 dataset. We will use different optimizers and compare their convergence speed. First we import the libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always check that we are running on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU. This is important so things run faster.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. You should probably not do this.\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will classify images from the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. \n",
    "CIFAR10 has 60000 colour images of size 32x32 equally distributed in 10 classes.\n",
    "* You should load this dataset (hint: it is a built-in dataset in pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainset = ...\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "testset = ...\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make a CNN to train on the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        #...\n",
    "    def forward(self, x):\n",
    "        #...\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the training as a function so we can easily re-use it.\n",
    "def train(model, optimizer, num_epochs=10):\n",
    "    train_acc_all = []\n",
    "    test_acc_all = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "        model.train()\n",
    "        #For each epoch\n",
    "        train_correct = 0\n",
    "        for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            output = model(data)\n",
    "            #Compute the loss\n",
    "            loss = F.nll_loss(torch.log(output), target)\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            #Compute how many were correctly classified\n",
    "            predicted = output.argmax(1)\n",
    "            train_correct += (target==predicted).sum().cpu().item()\n",
    "        #Comput the test accuracy\n",
    "        test_correct = 0\n",
    "        model.eval()\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            predicted = output.argmax(1).cpu()\n",
    "            test_correct += (target==predicted).sum().item()\n",
    "        train_acc = train_correct/len(trainset)\n",
    "        test_acc = test_correct/len(testset)\n",
    "        train_acc_all.append(train_acc)\n",
    "        test_acc_all.append(test_acc)\n",
    "        print(\"Accuracy train: {train:.1f}%\\t test: {test:.1f}%\".format(test=100*test_acc, train=100*train_acc))\n",
    "    return test_acc_all, train_acc_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Train the network and plot the training and test accuracys with the epoch number on the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, train_acc = train(model, optimizer)\n",
    "# ...\n",
    "# ...\n",
    "plt.legend(('Test error','Train eror'))\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss what you see. Are you overfitting to the training data? Do you not learn anything? What can you change to do better?\n",
    "\n",
    "* Repeat the above steps but using Adam as the optimizer. Use Pytorch's defaults parameters. Do you learn faster?\n",
    "* Which optimizer works best for you?\n",
    "* Plot the test and test errors for both SGD and Adam in one plot\n",
    "* Try adding Batch normalisation after your convolutional layers. Does it help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will attempt to create and train a ResNet.\n",
    "* Implement the Residual block as a network below using convolutional kernel size $3\\times3$ according to the figure below\n",
    "![Residual block](https://cdn-images-1.medium.com/max/800/1*D0F3UitQ2l5Q0Ak-tjEdJg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        # ...\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # ...\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a sanity of your residual block network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity test of your implementation\n",
    "C = 4\n",
    "res_block = ResNetBlock(C)\n",
    "assert(len(res_block.state_dict())==4)\n",
    "for w in res_block.state_dict().values():\n",
    "    w*=0\n",
    "x = torch.randn(32, C, 32,32)\n",
    "assert(torch.abs(res_block(x)-F.relu(x)).max()==0)\n",
    "assert(res_block.state_dict()['resblock.0.weight'].shape==(C, C, 3, 3))\n",
    "print(\"Passed sanity check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_in, n_features, num_res_blocks=5):\n",
    "        super(ResNet, self).__init__()\n",
    "        #First conv layers needs to output the desired number of features.\n",
    "        conv_layers = [nn.Conv2d(n_in, n_features, kernel_size=3, stride=1, padding=1),\n",
    "                       nn.ReLU()]\n",
    "        for i in range(num_res_blocks):\n",
    "            conv_layers.append(ResNetBlock(n_features))\n",
    "        self.res_blocks = nn.Sequential(*conv_layers)\n",
    "        self.fc = nn.Sequential(nn.Linear(32*32*n_features, 2048),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(2048, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512,10),\n",
    "                                nn.Softmax(dim=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.res_blocks(x)\n",
    "        #reshape x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our new resnet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "test_acc, train_acc = train(model, optimizer)\n",
    "plt.plot(test_acc)\n",
    "plt.plot(train_acc)\n",
    "plt.legend(('Test error','Train eror'))\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
